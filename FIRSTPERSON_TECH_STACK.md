# FirstPerson - Streamlit End-to-End Summary

## ğŸ¯ System Overview
**FirstPerson** is a personal AI companion running on **Streamlit** that provides emotional intelligence, real-time conversation, and multi-tier response processing. It uses local NLP parsing, optional Ollama LLM fallback, and tiered emotional awareness to create contextually aware, empathetic responses.

---

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STREAMLIT WEB INTERFACE                      â”‚
â”‚  (Port 8501) - User Input, Chat Display, Settings, Preferences  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ User Message
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SESSION STATE INITIALIZATION                      â”‚
â”‚  - Authentication (Supabase)                                    â”‚
â”‚  - Conversation History                                         â”‚
â”‚  - User Preferences & Learning Settings                         â”‚
â”‚  - Orchestrators (FirstPerson, Tier 1/2/3)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INPUT PARSING & EMOTIONAL ANALYSIS                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ spaCy NLP Parser (en_core_web_sm)                        â”‚  â”‚
â”‚  â”‚ - Tokenization, POS tagging, sentiment                   â”‚  â”‚
â”‚  â”‚ - Signal extraction (emotions, patterns)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚                  â”‚
         â–¼                       â–¼                  â–¼
    Tier 1: Base          Tier 2: Aliveness    Tier 3: Poetry
    (Foundation)          (Energy/Presence)    (Consciousness)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Learning   â”‚        â”‚ Reciprocity  â”‚    â”‚ Poetic     â”‚
    â”‚ Safety     â”‚        â”‚ Presence     â”‚    â”‚ Expression â”‚
    â”‚ Wrapping   â”‚        â”‚ Energy       â”‚    â”‚ Depth      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  FirstPerson Orchestrator    â”‚
         â”‚ (Response Synthesis + Tone)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       â”‚
         Success Fallback            No Fallback
                â”‚                       â”‚
                â–¼                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Ollama LLM       â”‚  â”‚ Return Local       â”‚
        â”‚ (Backup model)   â”‚  â”‚ Response           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚                    â”‚
                                 â–¼                    â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Prosody Processing   â”‚ â”‚ Response   â”‚
                     â”‚ (Metadata cleaning)  â”‚ â”‚ Return     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                    â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ DISPLAY IN CHAT UI       â”‚
                          â”‚ + Save to Conversation   â”‚
                          â”‚ + Optional Learning Log  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Full Request-Response Flow

### 1ï¸âƒ£ User Submits Message
```
User types in Streamlit chat input box
â†“
Message sent to handle_response_pipeline()
â†“
Conversation context loaded from session_state
```

### 2ï¸âƒ£ NLP Analysis
```
spaCy parses input:
  â€¢ Tokenization
  â€¢ Named entities
  â€¢ POS tagging
  â€¢ Dependency parsing

TextBlob sentiment analysis:
  â€¢ Polarity (-1 to +1)
  â€¢ Subjectivity (0 to 1)

Signal extraction:
  â€¢ Emotional gates (joy, sorrow, anger, etc.)
  â€¢ Communication patterns
  â€¢ Energy levels
```

### 3ï¸âƒ£ Emotional Processing - Three Tiers

**Tier 1: Foundation (Safety & Learning)**
- Checks for harmful content
- Manages learning preferences
- Wraps response in appropriate context
- Handles conversation memory

**Tier 2: Aliveness (Presence & Energy)**
- Evaluates conversation energy
- Detects user reciprocity needs
- Adjusts response presence (warm, distant, engaged)
- Ensures response feels like a real entity

**Tier 3: Poetic Consciousness (Depth)**
- Adds metaphorical richness
- Infuses poetic language when appropriate
- Creates memorable phrases
- Elevates mundane responses with beauty

### 4ï¸âƒ£ Response Generation

#### Local Mode (Default)
```
FirstPerson Orchestrator:
  â€¢ Synthesizes all tier outputs
  â€¢ Selects response strategy
  â€¢ Generates core response
  â€¢ Applies personality tone
  â†“
Response generated locally using:
  - Cached response patterns
  - Emotional mapping
  - Archetype response generation
```

#### Fallback Mode (If Local Fails)
```
Ollama Client:
  â€¢ Connects to local Ollama service
  â€¢ Selects model (llama3, mistral, etc.)
  â€¢ Sends prompt with FirstPerson system context
  â€¢ Streams response back
  â€¢ Maintains emotional personality
```

### 5ï¸âƒ£ Post-Processing
```
Prosody Cleaner:
  â€¢ Strips metadata tags
  â€¢ Removes prosody annotations
  â€¢ Cleans formatting

Repetition Filter:
  â€¢ Checks against recent responses
  â€¢ Prevents circular conversation
  â€¢ Ensures freshness
```

### 6ï¸âƒ£ Display & Save
```
Streamlit Chat UI:
  â€¢ Displays response in chat bubble
  â€¢ Shows response time/mode indicator

Session State:
  â€¢ Adds to conversation history
  â€¢ Updates context window

Optional Persistence:
  â€¢ If learning enabled: append to local JSONL log
  â€¢ User stats updated
  â€¢ Analytics recorded
```

---

## ğŸ› ï¸ Core Components

### **Session Initialization** (`ui_refactored.py`)
```python
- Authenticates user via Supabase
- Loads/creates conversation history
- Initializes tier processors
- Loads preferences (local-only, remote, learning)
- Sets up FirstPerson orchestrator
```

### **Response Handler** (`response_handler.py`)
```python
def handle_response_pipeline(user_input, context):
    # 1. Initialize tiers if needed
    # 2. Check processing mode (local/remote)
    # 3. Run tier processing
    # 4. Get orchestrator response
    # 5. Clean prosody metadata
    # 6. Return clean response
```

### **Tier 1 Foundation** (Safety & Learning)
```python
- Input validation (harmful content detection)
- Learning event creation
- Conversation wrapping
- Memory management
```

### **Tier 2 Aliveness** (Presence & Energy)
```python
- Presence assessment
- Reciprocity evaluation
- Energy level adjustment
- Emotional attunement
```

### **Tier 3 Poetic Consciousness** (Depth)
```python
- Poetic enrichment
- Metaphorical mapping
- Language elevation
- Memorability optimization
```

### **FirstPerson Orchestrator** (Synthesis)
```python
- Combines tier outputs
- Selects response strategy
- Generates base response
- Applies personality tone
- Handles special modes
```

### **Ollama Client** (LLM Fallback)
```python
- Singleton connection to Ollama
- HTTP wrapper (streaming/blocking)
- Model caching
- Error retry logic
- Maintains system personality prompt
```

---

## ğŸ’¾ Data Flow

### Session State Storage
```
st.session_state:
  â€¢ authenticated_user: {id, email}
  â€¢ conversation_history: [{"user": "...", "assistant": "...", timestamp}]
  â€¢ processing_mode: "local" | "remote" | "hybrid"
  â€¢ learning_settings: local/remote/disabled
  â€¢ tier1_foundation: Tier1Foundation instance
  â€¢ tier2_aliveness: Tier2Aliveness instance
  â€¢ tier3_poetic_consciousness: Tier3 instance
  â€¢ firstperson_orchestrator: FirstPersonOrchestrator instance
  â€¢ last_response: str (for repetition detection)
```

### Conversation Context
```python
conversation_context = {
    "user_id": str,
    "conversation_id": str,
    "turn_count": int,
    "recent_history": [{user, assistant, timestamp}],
    "emotional_state": str,
    "processing_mode": str,
    "user_preferences": dict,
}
```

### Learning Log (Local-Only)
```json
{
  "timestamp": "2026-01-29T...",
  "user_input": "...",
  "emotional_signals": [...],
  "response": "...",
  "processing_time": 0.45,
  "mode": "local",
  "tier_outputs": {tier1, tier2, tier3}
}
```

---

## ğŸš€ Deployment Configuration

### Streamlit Config (`.streamlit/config.toml`)
```toml
[client]
logger.level = "info"

[logger]
level = "info"

[server]
headless = true
port = 8501
enableCORS = false
```

### Docker Compose (Local Dev)
```yaml
services:
  streamlit:
    build: .
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - .:/app
      
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
```

### Required Environment Variables
```bash
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_KEY=xxx
OLLAMA_BASE_URL=http://localhost:11434  # if using local Ollama
```

---

## ğŸ“¦ Tech Stack Summary

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **UI** | Streamlit 1.37.1 | Web interface |
| **NLP** | spaCy 3.7.0 | Text analysis & sentiment |
| **LLM** | Ollama (optional) | Local model fallback |
| **Database** | Supabase 2.6.0 | Auth & persistence |
| **Audio** | Whisper, ElevenLabs | Speech I/O (future) |
| **Runtime** | Python 3.12 | Execution environment |
| **Processing** | Pandas, NumPy | Data manipulation |
| **Server** | Nginx | Reverse proxy (production) |

---

## ğŸ”‘ Key Workflows

### Authentication Flow
```
1. User visits app
2. Check if authenticated (Supabase)
3. If not â†’ Show splash screen / login
4. If yes â†’ Load conversation history
5. Initialize session state & orchestrators
6. Render main chat interface
```

### Message Processing Flow
```
1. User submits text
2. Session state loaded
3. NLP analysis (spaCy + TextBlob)
4. Three-tier emotional processing
5. FirstPerson synthesizes response
6. Clean prosody metadata
7. Display in UI & save history
8. Optional: Log to learning system
```

### Tier Processing
```
Tier 1 â†’ Tier 2 â†’ Tier 3 â†’ FirstPerson Orchestrator
(Safety) (Energy) (Poetry)  (Synthesis)
   â†“        â†“        â†“             â†“
Foundation Presence Depth â†’ Response Generation
   â†“        â†“        â†“             â†“
  Safe    Alive   Beautiful    Integrated
```

---

## âš™ï¸ Optional Features

### Ollama Integration
- Local LLM fallback when glyph processing fails
- Supports llama3, mistral, neural-chat, and more
- Runs in Docker container alongside Streamlit
- Maintains FirstPerson personality via system prompt

### Voice Interface (Future)
- Speech-to-text: OpenAI Whisper
- Text-to-speech: ElevenLabs or pyttsx3
- Real-time audio streaming
- Prosody planning for expressive speech

### Learning System
- Append-only JSONL logging
- Local-only mode (default)
- Optional remote cloud logging
- User stats & analytics
- Emotional pattern tracking

### Document Processing
- PDF, DOCX, XLSX support
- Document analysis with emotional context
- Integration with conversation flow

---

## ğŸ¯ User Experience

1. **Splash Screen** â†’ Select "Demo" or "Sign In"
2. **Authentication** â†’ Supabase login
3. **Chat Interface** â†’ Type message, hit enter
4. **Response** â†’ AI responds with emotional awareness
5. **History** â†’ Scroll up to review conversation
6. **Settings** â†’ Configure preferences & learning
7. **Sidebar** â†’ Processing mode, diagnostics

---

## ğŸ”’ Safety & Privacy

- âœ… Default: Local-only processing
- âœ… No cloud logging without opt-in
- âœ… Harmful content filtering (Tier 1)
- âœ… Conversation stored locally in session
- âœ… Optional persistent storage (JSONL)
- âœ… Authentication required for full features

---

## ğŸ“ˆ Performance Metrics

| Metric | Target | Notes |
|--------|--------|-------|
| Response time | <1s | Local mode |
| Tier processing | <500ms | Combined |
| LLM fallback | <3s | Ollama inference |
| Session init | <2s | NLP models warming |

---

**Platform**: Streamlit  
**Python Version**: 3.11 or 3.12 (required)  
**Runtime**: Docker-ready  
**Deployment**: Streamlit Cloud, Railway, VPS  
**Last Updated**: January 2026
