"""Subordinate Bot Responder for FirstPerson.

The performer/actor layer: Fast, local response generation using existing glyphs.
NEVER learns, NEVER blocks, NEVER calls expensive APIs.

Pipeline:
  1. Receive user input
  2. Parse emotional context from Tier1/2/3
  3. Find best matching glyph
  4. Generate response from glyph
  5. Return immediately

Target: <100ms response time
"""

from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
import numpy as np
from scipy.spatial.distance import cosine


@dataclass
class SubordinateBotResponse:
    """Response generated by subordinate bot."""
    response_text: str
    glyph_name: str
    emotional_vector: List[float]
    confidence: float
    processing_time_ms: float
    method: str  # "matched" or "synthesized"


class SubordinateBotResponder:
    """Fast local responder using existing glyphs.
    
    Never creates new glyphs, never learns, never changes.
    It's a pure inference engine.
    """

    def __init__(
        self,
        tier1_foundation,
        tier2_aliveness,
        tier3_poetic_consciousness,
        glyph_library: Optional[Dict] = None,
    ):
        """Initialize subordinate bot.
        
        Args:
            tier1_foundation: Tier1 instance (for safety, wrapping)
            tier2_aliveness: Tier2 instance (for presence, energy)
            tier3_poetic_consciousness: Tier3 instance (for depth, beauty)
            glyph_library: Dictionary of available glyphs {glyph_name: glyph_data}
        """
        self.tier1 = tier1_foundation
        self.tier2 = tier2_aliveness
        self.tier3 = tier3_poetic_consciousness
        self.glyph_library = glyph_library or {}
        self.response_history = []

    def respond(
        self,
        user_input: str,
        conversation_context: Dict,
        emotional_vector: List[float],
    ) -> SubordinateBotResponse:
        """Generate response WITHOUT learning.
        
        Args:
            user_input: The user's message
            conversation_context: Conversation metadata
            emotional_vector: Parsed emotional vector from input
            
        Returns:
            SubordinateBotResponse with text and metadata
        """
        import time
        start_time = time.time()
        
        # Step 1: Find best matching glyph
        best_glyph_name, match_confidence = self._get_best_glyph_match(
            emotional_vector
        )
        
        # Step 2: Generate response from glyph
        if best_glyph_name and match_confidence > 0.3:  # Decent match
            response_text, method = self._generate_response_from_glyph(
                best_glyph_name,
                user_input,
                conversation_context,
            )
        else:  # No good match - use fallback
            response_text, method = self._generate_fallback_response(
                user_input,
                conversation_context,
            )
            best_glyph_name = "fallback"
            match_confidence = 0.0

        # Defensive: if the generated response looks like a poetic glyph description
        # (long, contains poetic markers or the glyph description), override it with
        # a short human-style reply to keep subordinate grounded.
        try:
            rt_lower = (response_text or "").lower()
            poetic_markers = (
                "fullness",
                "steeped",
                "ecstatic",
                "joy so",
                "bliss",
                "saturat",
                "still",
                "mourning",
                "sanctify",
                "poetic",
                "lyric",
            )

            is_long = len((response_text or "").split()) > 12
            has_poetic = any(m in rt_lower for m in poetic_markers)

            # Also check if the glyph entry has a description that matches the response
            glyph_desc = None
            if best_glyph_name and best_glyph_name in self.glyph_library:
                glyph_desc = (self.glyph_library[best_glyph_name].get("description") or "").strip().lower()

            if (is_long and has_poetic) or (glyph_desc and glyph_desc and glyph_desc in rt_lower):
                # If user is overwhelmed prefer the overwhelm template
                ui = (user_input or "").lower()
                overwhelm_kw = [
                    "overwhelm",
                    "overwhelmed",
                    "too much",
                    "drowning",
                    "can't breathe",
                    "cant breathe",
                ]
                if any(k in ui for k in overwhelm_kw):
                    response_text = self._human_overwhelm_response(user_input)
                else:
                    # infer emotion from glyph name if possible
                    inferred_emotion = None
                    name = (best_glyph_name or "").lower()
                    if any(k in name for k in ("sad", "grief", "mourning", "ache")):
                        inferred_emotion = "sad"
                    elif any(k in name for k in ("anger", "frustration")):
                        inferred_emotion = "angry"
                    elif any(k in name for k in ("fear", "anxiety", "panic")):
                        inferred_emotion = "anxious"
                    elif any(k in name for k in ("joy", "relief", "happy", "bliss")):
                        inferred_emotion = "joy"
                    response_text = self._human_style_response(inferred_emotion, user_input)
                method = "matched"
        except Exception:
            # non-fatal: if anything goes wrong, keep original response_text
            pass
        
        # Step 3: Apply tier processing (safety, presence)
        # NOTE: Tier3 (poetic enrichment) is intentionally NOT applied here
        # because the subordinate responder must remain fast, grounded, and
        # non-poetic. Tier3 belongs to the dominant/deep layer only.
        response_text = self.tier1.wrap_response(response_text, conversation_context)
        response_text = self.tier2.attune_presence(response_text, conversation_context)
        
        # Step 4: Calculate processing time
        processing_time_ms = (time.time() - start_time) * 1000
        
        # Create response object
        response = SubordinateBotResponse(
            response_text=response_text,
            glyph_name=best_glyph_name,
            emotional_vector=emotional_vector,
            confidence=match_confidence,
            processing_time_ms=processing_time_ms,
            method=method,
        )
        
        # Store for dominant bot to observe
        self.response_history.append(
            {
                "user_input": user_input,
                "response": response_text,
                "glyph": best_glyph_name,
                "confidence": match_confidence,
                "emotional_vector": emotional_vector,
            }
        )
        
        return response

    def _get_best_glyph_match(
        self,
        emotional_vector: List[float],
        top_k: int = 3,
    ) -> Tuple[Optional[str], float]:
        """Find best matching glyph using cosine similarity.
        
        Args:
            emotional_vector: Current emotional vector
            top_k: Return top K matches
            
        Returns:
            (best_glyph_name, match_confidence)
        """
        if not self.glyph_library:
            return None, 0.0
        
        query_vector = np.array(emotional_vector)
        similarities = {}
        
        for glyph_name, glyph_data in self.glyph_library.items():
            glyph_vector = np.array(glyph_data.get("emotional_vector", []))
            
            if len(glyph_vector) != len(query_vector):
                continue  # Dimension mismatch
            
            # Cosine similarity: higher is better (range 0-1)
            similarity = 1 - cosine(query_vector, glyph_vector)
            similarities[glyph_name] = similarity
        
        if not similarities:
            return None, 0.0
        
        # Return best match
        best_glyph = max(similarities, key=similarities.get)
        best_confidence = similarities[best_glyph]
        
        return best_glyph, best_confidence

    def _generate_response_from_glyph(
        self,
        glyph_name: str,
        user_input: str,
        conversation_context: Dict,
    ) -> Tuple[str, str]:
        """Generate response using a matched glyph.
        
        Args:
            glyph_name: Name of matched glyph
            user_input: User's message
            conversation_context: Conversation metadata
            
        Returns:
            (response_text, method="matched")
        """
        # Allow generating a response based on glyph_name even if the glyph
        # isn't present in the library (we use glyph name as emotional direction).
        glyph = self.glyph_library.get(glyph_name, {})

        # Simplified mapping: use glyph name for emotional direction only.
        # Return short, human, grounded responses (no poetry, no Tier3 here).
        name = (glyph_name or "").lower()
        ui = (user_input or "").lower()

        # Overwhelm detection: if the user's input contains common overwhelm cues,
        # return the special human, space-creating response.
        overwhelm_keywords = [
            "overwhelm",
            "overwhelmed",
            "too much",
            "can't",
            "cant",
            "drowning",
            "swamped",
            "buried",
            "holding a lot",
            "can't breathe",
            "cant breathe",
            "so much",
            "overloaded",
            "can't handle",
            "cant handle",
        ]
        if any(k in ui for k in overwhelm_keywords):
            return self._human_overwhelm_response(user_input), "matched"

        # Map glyph name to a short emotion label for human-style phrasing
        emotion = None
        if any(k in name for k in ("sad", "grief", "mourning", "ache")):
            emotion = "sad"
        elif any(k in name for k in ("anger", "frustration")):
            emotion = "angry"
        elif any(k in name for k in ("fear", "anxiety", "panic")):
            emotion = "anxious"
        elif any(k in name for k in ("joy", "relief", "happy")):
            emotion = "joy"
        elif any(w in ui for w in ("tired", "exhausted", "beat", "sleepy")):
            emotion = "tired"

        # Use human-style helper to generate a short, casual reply
        if emotion:
            return self._human_style_response(emotion, user_input), "matched"

        # Default matched response (short and casual)
        return self._human_style_response(None, user_input), "matched"

    def _human_style_response(self, emotion: Optional[str], user_input: str) -> str:
        """Produce a short, casual human-sounding response.

        Uses a random opener, a light empathy marker, and an emotion-guided question.
        """
        import random

        openers = ["Yeah.", "Yah.", "Gotcha.", "Okay.", "Mm.", "Alright."]
        empathy = [
            "I hear you.",
            "I get that.",
            "Makes sense.",
            "I get why you'd feel that.",
            "That tracks.",
        ]

        if emotion == "tired":
            question = "What's got you so worn out?"
        elif emotion == "sad":
            question = "What’s weighing on you?"
        elif emotion == "angry":
            question = "What set that off?"
        elif emotion == "anxious":
            question = "What’s making it feel like that?"
        elif emotion == "joy":
            question = "Nice — what happened?"
        else:
            question = "What’s going on?"

        return f"{random.choice(openers)} {random.choice(empathy)} {question}"

    def _human_overwhelm_response(self, user_input: str) -> str:
        """Produce a short, grounded 'overwhelm' style reply that creates space.

        Structure:
        - human exhale opener
        - name the weight
        - optional gentle noticing about care/support
        - agency-based invitation
        """
        import random

        openers = [
            "Wow.",
            "Oof.",
            "Man.",
            "Yeah, that’s a lot.",
            "Damn.",
        ]

        weight = [
            "Sounds like you're holding a lot.",
            "That's quite a load.",
            "That's a heavy mix to deal with.",
            "Feels like everything hit at once.",
            "That's a lot for one person to carry.",
        ]

        noticing = [
            "One thing I'm not hearing is where you're getting care in all that.",
            "I’m not sure where you’re getting support in the middle of all that.",
            "I don’t hear much room for you in that list.",
            "I’m not seeing where you get to breathe in all of that.",
            None,
        ]

        invitations = [
            "If you wanna talk more about it, I'm here to listen.",
            "If it helps to talk through any of it, I’m around.",
            "If you feel like unpacking it, I’m here.",
            "If you want to say more, I’m listening.",
        ]

        opener = random.choice(openers)
        weight_line = random.choice(weight)
        notice_line = random.choice(noticing)
        invite = random.choice(invitations)

        if notice_line:
            return f"{opener} {weight_line} {notice_line} {invite}"
        return f"{opener} {weight_line} {invite}"

    def _generate_fallback_response(
        self,
        user_input: str,
        conversation_context: Dict,
    ) -> Tuple[str, str]:
        """Generate fallback response when no glyph matches.
        
        Args:
            user_input: User's message
            conversation_context: Conversation metadata
            
        Returns:
            (response_text, method="fallback")
        """
        # Rotate through short, casual fallback patterns for a more human feel
        fallbacks = [
            "Got it. What’s going on?",
            "Okay. Say more.",
            "Alright — walk me through it.",
            "Yeah, I’m here. What happened?",
            "Mm, okay. What part is hitting you the most?",
            "I get you. Tell me more.",
        ]
        import random
        return random.choice(fallbacks), "fallback"

    def update_glyph_library(self, glyph_library: Dict) -> None:
        """Update available glyphs (called when dominant bot creates new ones).
        
        Args:
            glyph_library: New/updated glyph dictionary
        """
        self.glyph_library = glyph_library